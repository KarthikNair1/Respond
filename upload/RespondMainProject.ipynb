{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import time\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.models import load_model\n",
    "\n",
    "from watson_developer_cloud import ToneAnalyzerV3\n",
    "from watson_developer_cloud import NaturalLanguageUnderstandingV1\n",
    "from watson_developer_cloud.natural_language_understanding_v1 \\\n",
    "  import Features, EntitiesOptions, KeywordsOptions\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitting job with file\n",
      "Job created\n",
      "Checking job transcription status: in_progress\n",
      "Trying in another 30 seconds\n",
      "Checking job transcription status: in_progress\n",
      "Trying in another 30 seconds\n",
      "Checking job transcription status: transcribed\n",
      "{'monologues': [{'speaker': 0, 'elements': [{'type': 'text', 'value': 'Hello', 'ts': 0.8099999999999999, 'end_ts': 1.14, 'confidence': 1.0}, {'type': 'punct', 'value': ', '}, {'type': 'text', 'value': 'this', 'ts': 1.14, 'end_ts': 1.38, 'confidence': 1.0}, {'type': 'punct', 'value': ' '}, {'type': 'text', 'value': 'is', 'ts': 1.38, 'end_ts': 1.5, 'confidence': 1.0}, {'type': 'punct', 'value': ' '}, {'type': 'text', 'value': 'a', 'ts': 1.5, 'end_ts': 1.5899999999999999, 'confidence': 0.98}, {'type': 'punct', 'value': ' '}, {'type': 'text', 'value': 'test', 'ts': 1.5899999999999999, 'end_ts': 2.2199999999999998, 'confidence': 1.0}, {'type': 'punct', 'value': '.'}]}]}\n"
     ]
    }
   ],
   "source": [
    "#Code for speech to text conversion using RevSpeech API\n",
    "\n",
    "API_KEY = \"Bearer 01GQPjLQxzjnRB1lkzQ7ptri6wxAO1CYUbkZ3jkJiHZGoyYhT1csCeFNa-FW1aDKBS3HVUTTvWmmGdDyd6XP_A7zBeHZM\"\n",
    "HEADERS = {'Authorization': API_KEY}\n",
    "\n",
    "def submit_job_url(media_url):\n",
    "    url = \"https://api.rev.ai/revspeech/v1beta/jobs\"\n",
    "    payload = {'media_url': media_url,\n",
    "               'metadata': \"Test\"}\n",
    "    request = requests.post(url, headers=HEADERS, json=payload)\n",
    "\n",
    "    if request.status_code != 200:\n",
    "        raise\n",
    "\n",
    "    response_body = request.json()\n",
    "    return response_body['id']\n",
    "\n",
    "def submit_job_file(file):\n",
    "    url = \"https://api.rev.ai/revspeech/v1beta/jobs\"\n",
    "    files = { 'media': (file, open(file, 'rb'), 'audio/mp3') }\n",
    "    request = requests.post(url, headers=HEADERS, files=files)\n",
    "    if request.status_code != 200:\n",
    "        raise\n",
    "\n",
    "    response_body = request.json()\n",
    "    return response_body['id']\n",
    "\n",
    "def view_job(id=59594172):\n",
    "    url = f'https://api.rev.ai/revspeech/v1beta/jobs/{id}'\n",
    "    request = requests.get(url, headers=HEADERS)\n",
    "\n",
    "    if request.status_code != 200:\n",
    "        raise\n",
    "\n",
    "    response_body = request.json()\n",
    "    return response_body\n",
    "\n",
    "def get_transcript(id='59594172'):\n",
    "    url = f'https://api.rev.ai/revspeech/v1beta/jobs/{id}/transcript'\n",
    "    headers = HEADERS.copy()\n",
    "    headers['Accept'] = 'application/vnd.rev.transcript.v1.0+json'\n",
    "    request = requests.get(url, headers=headers)\n",
    "\n",
    "    if request.status_code != 200:\n",
    "        raise\n",
    "\n",
    "    response_body = request.json()\n",
    "    return response_body\n",
    "\n",
    "def test_workflow_with_url(url):\n",
    "    print (\"Submitting job with URL\")\n",
    "    id = submit_job_url(url)\n",
    "    print (\"Job created\")\n",
    "    view_job(id)\n",
    "\n",
    "    while True:\n",
    "        job = view_job(id)\n",
    "        status = job[\"status\"]\n",
    "        print (f'Checking job transcription status: { status }')\n",
    "        if status == \"transcribed\":\n",
    "            break\n",
    "        if status == \"failed\":\n",
    "            raise\n",
    "\n",
    "        print (\"Trying in another 30 seconds\")\n",
    "        time.sleep(30)\n",
    "\n",
    "    return get_transcript(id)\n",
    "\n",
    "def test_workflow_with_file(file):\n",
    "    print (\"Submitting job with file\")\n",
    "    id = submit_job_file(file)\n",
    "    print (\"Job created\")\n",
    "    view_job(id)\n",
    "\n",
    "    while True:\n",
    "        job = view_job(id)\n",
    "        status = job[\"status\"]\n",
    "        print (f'Checking job transcription status: { status }')\n",
    "        if status == \"transcribed\":\n",
    "            break\n",
    "        if status == \"failed\":\n",
    "            raise\n",
    "\n",
    "        print (\"Trying in another 30 seconds\")\n",
    "        time.sleep(30)\n",
    "\n",
    "    return get_transcript(id)\n",
    "\n",
    "file = \"test.mp3\"\n",
    "print(test_workflow_with_file(file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#List of manually created datapoints for urgency rating algorithm.\n",
    "urgencyList = {\n",
    "    \"The electricity in my neighborhood is out. Can you bring it back up? I just want power.\" : 1,\n",
    "    \"This is my luckiest day ever. I am so happy. I just ate a cookie. It was delicious. \" : 1,\n",
    "    \"Can you bring me tasty food? I want to enjoy my 18\\'th birthday. I move to college next week, so it would be great if you could do this.\" : 1,\n",
    "    \"My son has a mild headache. Can you help me? I am worried about his health, and he is only 5 years old.\" : 1,\n",
    "    \"I feel slightly nauseous after drinking coffee for the first time in a long time. What medicines should I take?\" : 1,\n",
    "    \"I fell and scraped my knee. Now I am bleeding and I'm worried about a bacterial infection.\" : 2,\n",
    "    \"My daughter just broke her pinky finger and it hurts her quite a bit. I think she will be okay, but can I get medical assistance.\" : 2,\n",
    "    \"I tripped and had a concussion at work, and it hurts a lot. I feel like vomiting. I need help soon, or I will faint.\" : 2,\n",
    "    \"My grandfather is coughing a lot. I think he has the flu and I\\'m worried for his health. We don\\'t have any medicine\" : 2,\n",
    "    \"A tree just fell and destroyed our entire house. This is horrible. I\\'ve lived here for 20 years, and now it's all gone?\" : 2,\n",
    "    \"The water supply is contaminated. We don\\'t have any clean water. Please bring us water immediately, or we may die. \" : 3,\n",
    "    \"A tree just fell on my husband\\'s back. I can\\'t even hear his heartbeat anymore. Oh god, please help immediately, before he dies.\" : 3,\n",
    "    \"My father just had a heart attack. He's writhing in pain, I've never seen him suffer like this before. Please, this is extremely urgent. He could die!\" : 3,\n",
    "    \"I just found both of my parents dead in the living room. Oh god, there's blood everywhere. This can't be real. How could anybody do this? This is the worst thing I've ever seen.\" : 3,\n",
    "    \"Please, help, this is extremely urgent. A big boulder just trapped ten of us in a cave, and we can't escape. If we don't get help immediately, we will soon die from lack of oxygen.\" : 3,\n",
    "    }\n",
    "\n",
    "#IBM Natural Language Understanding API\n",
    "nlu = NaturalLanguageUnderstandingV1(version='2018-09-15',username='3298b4bc-e9a7-4e26-accb-5969030597d4',password='XRR7ex4OCw2q')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vector(sentence):\n",
    "    #returns a feature vector from the emotional decomposition(sadness, joy, fear, disgust, anger, sentiment) of a sentence.\n",
    "    response = nlu.analyze(text=sentence,features=Features(entities=EntitiesOptions(emotion=True,sentiment=True,limit=2), keywords=KeywordsOptions(emotion=True,sentiment=True,limit=2))).get_result()\n",
    "    accept = ['sadness', 'joy','fear','disgust','anger']\n",
    "    vec = np.zeros(6)\n",
    "    cnt = 0\n",
    "    for g in response['keywords']:\n",
    "        \n",
    "        if('emotion' in g):\n",
    "            cnt+=1\n",
    "            for i in range(5):\n",
    "                vec[i] += g['emotion'][accept[i]]\n",
    "            vec[5] += g['sentiment']['score']\n",
    "\n",
    "    for i in range(6):\n",
    "        vec[i]/=cnt\n",
    "    \n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build a neural network for evaluating urgency and saves it\n",
    "def build_neural_model():\n",
    "    trainx = np.zeros( (len(urgencyList),6) )\n",
    "    trainy = np.zeros( (len(urgencyList),1) )\n",
    "    ptr = 0\n",
    "    for i in urgencyList:\n",
    "        trainx[ptr,:] = get_vector(i)\n",
    "        trainy[ptr] = urgencyList[i]\n",
    "        ptr+=1\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=6, activation = 'relu', input_dim=6))\n",
    "    model.add(Dense(units=4, activation = 'relu'))\n",
    "    model.add(Dense(units=1, activation = 'linear'))\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    model.fit(trainx, trainy, epochs=750, verbose=0)\n",
    "    model.save('neumodel.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitting job with file\n",
      "Job created\n",
      "Checking job transcription status: in_progress\n",
      "Trying in another 30 seconds\n",
      "Checking job transcription status: in_progress\n",
      "Trying in another 30 seconds\n",
      "Checking job transcription status: in_progress\n",
      "Trying in another 30 seconds\n",
      "Checking job transcription status: in_progress\n",
      "Trying in another 30 seconds\n",
      "Checking job transcription status: in_progress\n",
      "Trying in another 30 seconds\n",
      "Checking job transcription status: in_progress\n",
      "Trying in another 30 seconds\n",
      "Checking job transcription status: transcribed\n",
      "Submitting job with file\n",
      "Job created\n",
      "Checking job transcription status: in_progress\n",
      "Trying in another 30 seconds\n",
      "Checking job transcription status: in_progress\n",
      "Trying in another 30 seconds\n",
      "Checking job transcription status: in_progress\n",
      "Trying in another 30 seconds\n",
      "Checking job transcription status: in_progress\n",
      "Trying in another 30 seconds\n",
      "Checking job transcription status: transcribed\n",
      "Submitting job with file\n",
      "Job created\n",
      "Checking job transcription status: in_progress\n",
      "Trying in another 30 seconds\n",
      "Checking job transcription status: in_progress\n",
      "Trying in another 30 seconds\n",
      "Checking job transcription status: transcribed\n",
      "[\"There's a forest fire in my neighborhood destroying everything in sight. All I can see, smoke and ash. Please help. My children are in danger. I can't let anything happen to them.\", \"My friend fell down and broke his knee. You'll be okay, but we need medical assistance as soon as possible.\", \"An earthquake just came out of nowhere and industry in the city. This is the worst natural disaster I've seen in my life. I can't believe this is happening. People are still trapped under rocks and will die if they are not saved. Please help.\"]\n"
     ]
    }
   ],
   "source": [
    "#speech to text translation\n",
    "fileprefix = \"test\"\n",
    "\n",
    "tests = []\n",
    "for i in range(1,4):\n",
    "\n",
    "    FullSet = test_workflow_with_file(fileprefix+str(i)+\".mp3\")['monologues'][0]['elements']\n",
    "    this_string = \"\"\n",
    "    for elem in FullSet:\n",
    "        this_string += elem['value']\n",
    "    tests.append(this_string)\n",
    "\n",
    "print(tests)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "build_neural_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.8239572]\n",
      " [1.6484303]\n",
      " [2.2522426]]\n"
     ]
    }
   ],
   "source": [
    "model = load_model('neumodel.h5')\n",
    "\n",
    "ptr = 0\n",
    "givenSents = tests\n",
    "totx = np.zeros( (len(givenSents),6))\n",
    "for i in givenSents:\n",
    "    totx[ptr,:] = get_vector(i)\n",
    "    ptr+=1\n",
    "print(model.predict(totx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
